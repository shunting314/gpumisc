//
// Generated by LLVM NVPTX Back-End
//

.version 8.0
.target sm_80
.address_size 64

	// .globl	sumrow_kernel_0d1d23d
.extern .shared .align 1 .b8 global_smem[];

.visible .entry sumrow_kernel_0d1d23d(
	.param .u64 sumrow_kernel_0d1d23d_param_0,
	.param .u64 sumrow_kernel_0d1d23d_param_1,
	.param .u32 sumrow_kernel_0d1d23d_param_2,
	.param .u32 sumrow_kernel_0d1d23d_param_3
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<89>;
	.reg .b32 	%r<173>;
	.reg .f32 	%f<94>;
	.reg .b64 	%rd<23>;

	ld.param.u64 	%rd2, [sumrow_kernel_0d1d23d_param_1];
	ld.param.u64 	%rd3, [sumrow_kernel_0d1d23d_param_0];
	mov.u32 	%r1, %tid.x;
	bfe.u32 	%r2, %r1, 6, 1;
	shl.b32 	%r4, %r1, 2;
	and.b32  	%r5, %r4, 252;
	mov.u32 	%r6, %ctaid.x;
	shl.b32 	%r3, %r6, 1;
	or.b32  	%r7, %r2, %r3;
	setp.lt.s32 	%p1, %r7, 4;
	shl.b32 	%r8, %r7, 11;
	or.b32  	%r9, %r5, %r8;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd1, %rd3, %rd4;
	@%p1 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:
	mov.u32 	%r78, 0;
	mov.pred 	%p42, -1;
	mov.u32 %r74, 0x0;
	mov.u32 %r75, 0x0;
	mov.u32 %r76, 0x0;
	mov.u32 %r77, 0x0;
	@%p42 ld.global.v4.b32 { %r74, %r75, %r76, %r77 }, [ %rd1 + 0 ];
	@!%p42 mov.u32 %r74, %r78;
	@!%p42 mov.u32 %r75, %r78;
	@!%p42 mov.u32 %r76, %r78;
	@!%p42 mov.u32 %r77, %r78;
	mov.b32 	%f13, %r74;
	mov.b32 	%f14, %r75;
	mov.b32 	%f15, %r76;
	mov.b32 	%f16, %r77;
	add.f32 	%f17, %f13, 0f00000000;
	add.f32 	%f18, %f14, 0f00000000;
	add.f32 	%f19, %f15, 0f00000000;
	add.f32 	%f20, %f16, 0f00000000;
	add.s64 	%rd14, %rd1, 1024;
	mov.u32 %r82, 0x0;
	mov.u32 %r83, 0x0;
	mov.u32 %r84, 0x0;
	mov.u32 %r85, 0x0;
	@%p42 ld.global.v4.b32 { %r82, %r83, %r84, %r85 }, [ %rd14 + 0 ];
	@!%p42 mov.u32 %r82, %r78;
	@!%p42 mov.u32 %r83, %r78;
	@!%p42 mov.u32 %r84, %r78;
	@!%p42 mov.u32 %r85, %r78;
	mov.b32 	%f21, %r82;
	mov.b32 	%f22, %r83;
	mov.b32 	%f23, %r84;
	mov.b32 	%f24, %r85;
	add.f32 	%f25, %f17, %f21;
	add.f32 	%f26, %f18, %f22;
	add.f32 	%f27, %f19, %f23;
	add.f32 	%f28, %f20, %f24;
	add.s64 	%rd15, %rd1, 2048;
	mov.u32 %r90, 0x0;
	mov.u32 %r91, 0x0;
	mov.u32 %r92, 0x0;
	mov.u32 %r93, 0x0;
	@%p42 ld.global.v4.b32 { %r90, %r91, %r92, %r93 }, [ %rd15 + 0 ];
	@!%p42 mov.u32 %r90, %r78;
	@!%p42 mov.u32 %r91, %r78;
	@!%p42 mov.u32 %r92, %r78;
	@!%p42 mov.u32 %r93, %r78;
	mov.b32 	%f29, %r90;
	mov.b32 	%f30, %r91;
	mov.b32 	%f31, %r92;
	mov.b32 	%f32, %r93;
	add.f32 	%f33, %f25, %f29;
	add.f32 	%f34, %f26, %f30;
	add.f32 	%f35, %f27, %f31;
	add.f32 	%f36, %f28, %f32;
	add.s64 	%rd16, %rd1, 3072;
	mov.u32 %r98, 0x0;
	mov.u32 %r99, 0x0;
	mov.u32 %r100, 0x0;
	mov.u32 %r101, 0x0;
	@%p42 ld.global.v4.b32 { %r98, %r99, %r100, %r101 }, [ %rd16 + 0 ];
	@!%p42 mov.u32 %r98, %r78;
	@!%p42 mov.u32 %r99, %r78;
	@!%p42 mov.u32 %r100, %r78;
	@!%p42 mov.u32 %r101, %r78;
	mov.b32 	%f37, %r98;
	mov.b32 	%f38, %r99;
	mov.b32 	%f39, %r100;
	mov.b32 	%f40, %r101;
	add.f32 	%f41, %f33, %f37;
	add.f32 	%f42, %f34, %f38;
	add.f32 	%f43, %f35, %f39;
	add.f32 	%f44, %f36, %f40;
	add.s64 	%rd17, %rd1, 4096;
	mov.u32 %r106, 0x0;
	mov.u32 %r107, 0x0;
	mov.u32 %r108, 0x0;
	mov.u32 %r109, 0x0;
	@%p42 ld.global.v4.b32 { %r106, %r107, %r108, %r109 }, [ %rd17 + 0 ];
	@!%p42 mov.u32 %r106, %r78;
	@!%p42 mov.u32 %r107, %r78;
	@!%p42 mov.u32 %r108, %r78;
	@!%p42 mov.u32 %r109, %r78;
	mov.b32 	%f45, %r106;
	mov.b32 	%f46, %r107;
	mov.b32 	%f47, %r108;
	mov.b32 	%f48, %r109;
	add.f32 	%f49, %f41, %f45;
	add.f32 	%f50, %f42, %f46;
	add.f32 	%f51, %f43, %f47;
	add.f32 	%f52, %f44, %f48;
	add.s64 	%rd18, %rd1, 5120;
	mov.u32 %r114, 0x0;
	mov.u32 %r115, 0x0;
	mov.u32 %r116, 0x0;
	mov.u32 %r117, 0x0;
	@%p42 ld.global.v4.b32 { %r114, %r115, %r116, %r117 }, [ %rd18 + 0 ];
	@!%p42 mov.u32 %r114, %r78;
	@!%p42 mov.u32 %r115, %r78;
	@!%p42 mov.u32 %r116, %r78;
	@!%p42 mov.u32 %r117, %r78;
	mov.b32 	%f53, %r114;
	mov.b32 	%f54, %r115;
	mov.b32 	%f55, %r116;
	mov.b32 	%f56, %r117;
	add.f32 	%f57, %f49, %f53;
	add.f32 	%f58, %f50, %f54;
	add.f32 	%f59, %f51, %f55;
	add.f32 	%f60, %f52, %f56;
	add.s64 	%rd19, %rd1, 6144;
	mov.u32 %r122, 0x0;
	mov.u32 %r123, 0x0;
	mov.u32 %r124, 0x0;
	mov.u32 %r125, 0x0;
	@%p42 ld.global.v4.b32 { %r122, %r123, %r124, %r125 }, [ %rd19 + 0 ];
	@!%p42 mov.u32 %r122, %r78;
	@!%p42 mov.u32 %r123, %r78;
	@!%p42 mov.u32 %r124, %r78;
	@!%p42 mov.u32 %r125, %r78;
	mov.b32 	%f61, %r122;
	mov.b32 	%f62, %r123;
	mov.b32 	%f63, %r124;
	mov.b32 	%f64, %r125;
	add.f32 	%f65, %f57, %f61;
	add.f32 	%f66, %f58, %f62;
	add.f32 	%f67, %f59, %f63;
	add.f32 	%f68, %f60, %f64;
	add.s64 	%rd20, %rd1, 7168;
	mov.u32 %r130, 0x0;
	mov.u32 %r131, 0x0;
	mov.u32 %r132, 0x0;
	mov.u32 %r133, 0x0;
	@%p42 ld.global.v4.b32 { %r130, %r131, %r132, %r133 }, [ %rd20 + 0 ];
	@!%p42 mov.u32 %r130, %r78;
	@!%p42 mov.u32 %r131, %r78;
	@!%p42 mov.u32 %r132, %r78;
	@!%p42 mov.u32 %r133, %r78;
	mov.b32 	%f69, %r130;
	mov.b32 	%f70, %r131;
	mov.b32 	%f71, %r132;
	mov.b32 	%f72, %r133;
	add.f32 	%f90, %f65, %f69;
	add.f32 	%f91, %f66, %f70;
	add.f32 	%f92, %f67, %f71;
	add.f32 	%f93, %f68, %f72;
	bra.uni 	$L__BB0_3;
$L__BB0_1:
	mov.u32 	%r14, 0;
	mov.pred 	%p2, 0;
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	@%p2 ld.global.v4.b32 { %r10, %r11, %r12, %r13 }, [ %rd1 + 0 ];
	@!%p2 mov.u32 %r10, %r14;
	@!%p2 mov.u32 %r11, %r14;
	@!%p2 mov.u32 %r12, %r14;
	@!%p2 mov.u32 %r13, %r14;
	add.s64 	%rd6, %rd1, 1024;
	mov.u32 %r18, 0x0;
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	mov.u32 %r21, 0x0;
	@%p2 ld.global.v4.b32 { %r18, %r19, %r20, %r21 }, [ %rd6 + 0 ];
	@!%p2 mov.u32 %r18, %r14;
	@!%p2 mov.u32 %r19, %r14;
	@!%p2 mov.u32 %r20, %r14;
	@!%p2 mov.u32 %r21, %r14;
	add.s64 	%rd7, %rd1, 2048;
	mov.u32 %r26, 0x0;
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	mov.u32 %r29, 0x0;
	@%p2 ld.global.v4.b32 { %r26, %r27, %r28, %r29 }, [ %rd7 + 0 ];
	@!%p2 mov.u32 %r26, %r14;
	@!%p2 mov.u32 %r27, %r14;
	@!%p2 mov.u32 %r28, %r14;
	@!%p2 mov.u32 %r29, %r14;
	add.s64 	%rd8, %rd1, 3072;
	mov.u32 %r34, 0x0;
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	mov.u32 %r37, 0x0;
	@%p2 ld.global.v4.b32 { %r34, %r35, %r36, %r37 }, [ %rd8 + 0 ];
	@!%p2 mov.u32 %r34, %r14;
	@!%p2 mov.u32 %r35, %r14;
	@!%p2 mov.u32 %r36, %r14;
	@!%p2 mov.u32 %r37, %r14;
	add.s64 	%rd9, %rd1, 4096;
	mov.u32 %r42, 0x0;
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	mov.u32 %r45, 0x0;
	@%p2 ld.global.v4.b32 { %r42, %r43, %r44, %r45 }, [ %rd9 + 0 ];
	@!%p2 mov.u32 %r42, %r14;
	@!%p2 mov.u32 %r43, %r14;
	@!%p2 mov.u32 %r44, %r14;
	@!%p2 mov.u32 %r45, %r14;
	add.s64 	%rd10, %rd1, 5120;
	mov.u32 %r50, 0x0;
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	mov.u32 %r53, 0x0;
	@%p2 ld.global.v4.b32 { %r50, %r51, %r52, %r53 }, [ %rd10 + 0 ];
	@!%p2 mov.u32 %r50, %r14;
	@!%p2 mov.u32 %r51, %r14;
	@!%p2 mov.u32 %r52, %r14;
	@!%p2 mov.u32 %r53, %r14;
	add.s64 	%rd11, %rd1, 6144;
	mov.u32 %r58, 0x0;
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	mov.u32 %r61, 0x0;
	@%p2 ld.global.v4.b32 { %r58, %r59, %r60, %r61 }, [ %rd11 + 0 ];
	@!%p2 mov.u32 %r58, %r14;
	@!%p2 mov.u32 %r59, %r14;
	@!%p2 mov.u32 %r60, %r14;
	@!%p2 mov.u32 %r61, %r14;
	add.s64 	%rd12, %rd1, 7168;
	mov.u32 %r66, 0x0;
	mov.u32 %r67, 0x0;
	mov.u32 %r68, 0x0;
	mov.u32 %r69, 0x0;
	@%p2 ld.global.v4.b32 { %r66, %r67, %r68, %r69 }, [ %rd12 + 0 ];
	@!%p2 mov.u32 %r66, %r14;
	@!%p2 mov.u32 %r67, %r14;
	@!%p2 mov.u32 %r68, %r14;
	@!%p2 mov.u32 %r69, %r14;
	mov.f32 	%f90, 0f00000000;
	mov.f32 	%f91, %f90;
	mov.f32 	%f92, %f90;
	mov.f32 	%f93, %f90;
$L__BB0_3:
	and.b32  	%r155, %r1, 1;
	or.b32  	%r156, %r3, %r155;
	setp.lt.s32 	%p85, %r156, 4;
	and.b32  	%r157, %r1, 31;
	add.f32 	%f73, %f90, %f91;
	add.f32 	%f74, %f92, %f73;
	add.f32 	%f75, %f93, %f74;
	setp.eq.s32 	%p82, %r157, 0;
	mov.b32 	%r139, %f75;
	shfl.sync.bfly.b32 %r138, %r139, 0x10, 0x1f, 0xffffffff;
	mov.b32 	%f76, %r138;
	add.f32 	%f77, %f75, %f76;
	mov.b32 	%r141, %f77;
	shfl.sync.bfly.b32 %r140, %r141, 0x8, 0x1f, 0xffffffff;
	mov.b32 	%f78, %r140;
	add.f32 	%f79, %f77, %f78;
	mov.b32 	%r143, %f79;
	shfl.sync.bfly.b32 %r142, %r143, 0x4, 0x1f, 0xffffffff;
	mov.b32 	%f80, %r142;
	add.f32 	%f81, %f79, %f80;
	mov.b32 	%r145, %f81;
	shfl.sync.bfly.b32 %r144, %r145, 0x2, 0x1f, 0xffffffff;
	mov.b32 	%f82, %r144;
	add.f32 	%f83, %f81, %f82;
	mov.b32 	%r147, %f83;
	shfl.sync.bfly.b32 %r146, %r147, 0x1, 0x1f, 0xffffffff;
	mov.b32 	%f84, %r146;
	add.f32 	%f85, %f83, %f84;
	shr.u32 	%r158, %r1, 3;
	and.b32  	%r159, %r158, 4;
	shl.b32 	%r160, %r2, 3;
	or.b32  	%r161, %r160, %r159;
	mov.u32 	%r162, global_smem;
	add.s32 	%r148, %r162, %r161;
	mov.b32 	%r149, %f85;
	@%p82 st.shared.b32 [ %r148 + 0 ], %r149;
	bar.sync 	0;
	add.s32 	%r152, %r162, %r4;
	ld.shared.f32 	%f86, [%r152];
	mov.b32 	%r151, %f86;
	shfl.sync.bfly.b32 %r150, %r151, 0x1, 0x1f, 0xffffffff;
	mov.b32 	%f87, %r150;
	add.f32 	%f88, %f86, %f87;
	setp.lt.s32 	%p86, %r1, 4;
	setp.eq.s32 	%p87, %r155, 0;
	and.pred  	%p83, %p86, %p87;
	mov.b32 	%r153, %f88;
	@%p83 st.shared.b32 [ %r152 + 0 ], %r153;
	bar.sync 	0;
	add.s32 	%r164, %r162, %r160;
	ld.shared.f32 	%f89, [%r164];
	bar.sync 	0;
	shl.b32 	%r165, %r2, 2;
	add.s32 	%r166, %r162, %r165;
	st.shared.f32 	[%r166], %f89;
	bar.sync 	0;
	shl.b32 	%r167, %r155, 2;
	add.s32 	%r168, %r162, %r167;
	ld.shared.u32 	%r154, [%r168];
	mul.wide.s32 	%rd22, %r156, 4;
	add.s64 	%rd21, %rd2, %rd22;
	bfe.u32 	%r169, %r1, 1, 4;
	shr.u32 	%r170, %r1, 1;
	and.b32  	%r171, %r170, 2147483632;
	or.b32  	%r172, %r171, %r169;
	setp.eq.s32 	%p88, %r172, 0;
	and.pred  	%p84, %p85, %p88;
	@%p84 st.global.b32 [ %rd21 + 0 ], { %r154 };
	ret;

}
